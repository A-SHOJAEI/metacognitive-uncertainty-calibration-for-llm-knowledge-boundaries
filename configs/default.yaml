# Default configuration for Metacognitive Uncertainty Calibration
# This configuration balances performance with computational efficiency

seed: 42

data:
  dataset_name: "cais/mmlu"
  cache_dir: null  # Uses default cache directory
  max_length: 512
  batch_size: 4
  num_workers: 4
  train_split: "auxiliary_train"
  val_split: "validation"
  test_split: "test"
  subjects: null  # Use all subjects, can specify list like ["physics", "chemistry"]
  use_few_shot: true
  few_shot_examples: 5
  uncertainty_augmentation: true
  domain_split_ratio: 0.8

model:
  base_model_name: "gpt2-medium"
  num_choices: 4
  uncertainty_weight: 0.3
  explanation_weight: 0.2
  use_epistemic_estimation: false
  freeze_base_model: false
  epistemic_samples: 10
  dropout_rate: 0.1
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  temperature_init: 1.0

training:
  learning_rate: 0.00002
  weight_decay: 0.01
  num_epochs: 3
  warmup_steps: 500
  max_grad_norm: 1.0
  optimizer: "adamw"
  scheduler: "reduce_on_plateau"
  scheduler_patience: 3
  patience: 10
  save_every: 5
  log_every: 100
  eval_every: 1
  gradient_accumulation_steps: 4
  fp16: false
  early_stopping: true
  metric_for_best_model: "val_loss"

evaluation:
  n_bins: 15
  coverage_levels: [0.5, 0.7, 0.8, 0.9]
  uncertainty_types: ["knowledge_gap", "ambiguous", "reasoning_error"]
  compute_domain_metrics: true
  compute_calibration_plots: true
  compute_selective_prediction: true
  selective_coverage: 0.8
  statistical_tests: true
  bootstrap_samples: 1000

experiment:
  name: "metacognitive_uncertainty"
  run_name: null  # Auto-generated with timestamp
  tags:
    model_type: "metacognitive"
    dataset: "mmlu"
    framework: "pytorch"
  notes: "Baseline metacognitive uncertainty calibration experiment"
  tracking_uri: null  # Uses default MLflow tracking
  artifact_location: null
  log_model: true
  log_artifacts: true
  log_figures: true

inference:
  batch_size: 32
  max_length: 512
  return_explanations: true
  return_uncertainties: true
  temperature: 1.0
  top_k: null
  top_p: null
  num_beams: null
  do_sample: false